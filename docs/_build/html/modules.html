<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>RevelioNN Modules &mdash; RevelioNN  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Data" href="data.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            RevelioNN
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="scenarios.html">Usage Scenarios</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">RevelioNN Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.mapping_nets.single_mapping_net">single_mapping_net</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.in_features"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.in_features</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.num_neurons_list"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.num_neurons_list</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.forward"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_num_neurons_list"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.get_num_neurons_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_in_features"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.get_in_features()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">SingleMappingNet.get_num_neurons_list()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.mapping_nets.simultaneous_mapping_net">simultaneous_mapping_net</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder"><code class="docutils literal notranslate"><span class="pre">LayerDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.layers"><code class="docutils literal notranslate"><span class="pre">LayerDecoder.layers</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.forward"><code class="docutils literal notranslate"><span class="pre">LayerDecoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2"><code class="docutils literal notranslate"><span class="pre">LayerDecoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule"><code class="docutils literal notranslate"><span class="pre">MappingModule</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.common_layers"><code class="docutils literal notranslate"><span class="pre">MappingModule.common_layers</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.output_layers_list"><code class="docutils literal notranslate"><span class="pre">MappingModule.output_layers_list</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.sigmoid"><code class="docutils literal notranslate"><span class="pre">MappingModule.sigmoid</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.generate_layers"><code class="docutils literal notranslate"><span class="pre">MappingModule.generate_layers()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.forward"><code class="docutils literal notranslate"><span class="pre">MappingModule.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3"><code class="docutils literal notranslate"><span class="pre">MappingModule.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4"><code class="docutils literal notranslate"><span class="pre">MappingModule.generate_layers()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoder_channels"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.decoder_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_shared_neurons"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.num_shared_neurons</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_output_neurons"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.num_output_neurons</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_outs"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.num_outs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoders"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.decoders</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.forward"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_decoder_channels"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_decoder_channels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_shared_neurons"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_shared_neurons()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_output_neurons"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_output_neurons()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_outs"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_outs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_decoder_channels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_output_neurons()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_outs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9"><code class="docutils literal notranslate"><span class="pre">SimultaneousMappingNet.get_num_shared_neurons()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.main_module">main_module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.device"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.main_net"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.main_net</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.classes"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.classes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.load_model"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.evaluate_model"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.get_main_net"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_main_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.get_class_labels"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_class_labels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.get_device"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_device()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_class_labels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_device()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.get_main_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.main_module.MainModelProcessing.train_model"><code class="docutils literal notranslate"><span class="pre">MainModelProcessing.train_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.activation_extraction">activation_extraction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.device"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.main_net"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.main_net</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.layers_types_dict"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.layers_types_dict</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.layers_types"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.layers_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.layers_dict"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.layers_dict</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.activation"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.activation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.layers_for_research"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.layers_for_research</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.is_concatenate"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.is_concatenate</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_types"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_types()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.find_layer_predicate_recursive"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.find_layer_predicate_recursive()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.find_layers_types_recursive"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.find_layers_types_recursive()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.create_layers_dict"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.create_layers_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_dict"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_layer_name_by_number"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layer_name_by_number()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_activation"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_activation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.register_hooks"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.register_hooks()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.count_num_activations"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.count_num_activations()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_activations"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_activations()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.set_layers_for_research"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.set_layers_for_research()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_for_research"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_for_research()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor.get_main_net"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_main_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.count_num_activations()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id16"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.create_layers_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id17"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.find_layer_predicate_recursive()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id18"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.find_layers_types_recursive()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id19"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_activation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id20"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_activations()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id21"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layer_name_by_number()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id22"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id23"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_for_research()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id24"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_layers_types()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id25"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.get_main_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id26"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.register_hooks()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id27"><code class="docutils literal notranslate"><span class="pre">ActivationExtractor.set_layers_for_research()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.mapping_module">mapping_module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.device"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.activation_extractor"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.activation_extractor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.mapping_net"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.mapping_net</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.class_labels"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.class_labels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.evaluate_model"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.get_mapping_net"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_mapping_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.get_class_labels"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_class_labels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.get_activation_extractor"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_activation_extractor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.load_model"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id28"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id29"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id30"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_activation_extractor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id31"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_class_labels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id32"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.get_mapping_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id33"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.train_model_semisupervised"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.train_model_semisupervised()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.train_model_simultaneous"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.train_model_simultaneous()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing.train_model_single"><code class="docutils literal notranslate"><span class="pre">MappingModelProcessing.train_model_single()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.mapping_trainer">mapping_trainer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer"><code class="docutils literal notranslate"><span class="pre">MappingTrainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer.train_single_model"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.train_single_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.train_simultaneous_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer.evaluate_model"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id34"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.evaluate_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id35"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.train_simultaneous_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model_semisupervised"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.train_simultaneous_model_semisupervised()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id36"><code class="docutils literal notranslate"><span class="pre">MappingTrainer.train_single_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.concept_extraction">concept_extraction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.ontology"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.ontology</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.trainer"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.trainer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.create_subgraph"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.create_subgraph()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.order_concepts"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.order_concepts()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.exhaustive_search"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.exhaustive_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.linear_search"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.linear_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.heuristic_search"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.heuristic_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id37"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.create_subgraph()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id38"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.exhaustive_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id39"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.heuristic_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id40"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.linear_search()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id41"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.order_concepts()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.concept_extraction.ConceptExtractor.simultaneous_extraction"><code class="docutils literal notranslate"><span class="pre">ConceptExtractor.simultaneous_extraction()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.datasets">datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.img_labels"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.img_labels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.img_dir"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.img_dir</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.transform"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.transform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.__len__"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.__len__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.__getitem__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.MultiLabeledImagesDataset.labels"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.labels()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id42"><code class="docutils literal notranslate"><span class="pre">MultiLabeledImagesDataset.labels()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.img_labels"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.img_labels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.img_dir"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.img_dir</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.transform"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.transform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.unlabeled_idx"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.unlabeled_idx</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.__init__"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.__getitem__"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.__getitem__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.datasets.SemiSupervisedImagesDataset.separate_unlabeled"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.separate_unlabeled()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id43"><code class="docutils literal notranslate"><span class="pre">SemiSupervisedImagesDataset.separate_unlabeled()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.datasets.create_dataloader"><code class="docutils literal notranslate"><span class="pre">create_dataloader()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.early_stopping">early_stopping</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping"><code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.patience"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.patience</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.verbose"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.verbose</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.counter"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.counter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.best_score"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.best_score</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.early_stop"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.early_stop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.val_loss_min"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.val_loss_min</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.delta"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.delta</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.trace_func"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.trace_func</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.__call__"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.__call__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.early_stopping.EarlyStopping.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.save_checkpoint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id44"><code class="docutils literal notranslate"><span class="pre">EarlyStopping.save_checkpoint()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.occlusion">occlusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.occlusion.MultiLabelClassifier"><code class="docutils literal notranslate"><span class="pre">MultiLabelClassifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.occlusion.MultiLabelClassifier.classify_images"><code class="docutils literal notranslate"><span class="pre">MultiLabelClassifier.classify_images()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.occlusion.MultiLabelClassifier.get_config"><code class="docutils literal notranslate"><span class="pre">MultiLabelClassifier.get_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#revelionn.occlusion.MultiLabelClassifier.get_labels"><code class="docutils literal notranslate"><span class="pre">MultiLabelClassifier.get_labels()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.occlusion.perform_occlusion"><code class="docutils literal notranslate"><span class="pre">perform_occlusion()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.utils.explanation">utils.explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.explanation.explain_target_concept"><code class="docutils literal notranslate"><span class="pre">explain_target_concept()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.explanation.extract_concepts_from_img"><code class="docutils literal notranslate"><span class="pre">extract_concepts_from_img()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.explanation.to_main_observation"><code class="docutils literal notranslate"><span class="pre">to_main_observation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.explanation.to_mapping_observation"><code class="docutils literal notranslate"><span class="pre">to_mapping_observation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-revelionn.utils.model">utils.model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.model.convert_to_rvl_format"><code class="docutils literal notranslate"><span class="pre">convert_to_rvl_format()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.model.load_main_model"><code class="docutils literal notranslate"><span class="pre">load_main_model()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#revelionn.utils.model.load_mapping_model"><code class="docutils literal notranslate"><span class="pre">load_mapping_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">RevelioNN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">RevelioNN Modules</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/modules.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="revelionn-modules">
<h1>RevelioNN Modules<a class="headerlink" href="#revelionn-modules" title="Permalink to this heading"></a></h1>
<section id="module-revelionn.mapping_nets.single_mapping_net">
<span id="single-mapping-net"></span><h2>single_mapping_net<a class="headerlink" href="#module-revelionn.mapping_nets.single_mapping_net" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_nets.single_mapping_net.</span></span><span class="sig-name descname"><span class="pre">SingleMappingNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_neurons_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet" title="Permalink to this definition"></a></dt>
<dd><p>Single Mapping Network for RevelioNN.</p>
<p>It is a fully connected network that receives as input the layer activations reduced to a single dimension or the
concatenation of activations of convolutional network layers. It has a ReLU activation function in its hidden
layers and a sigmoid in its output. In connection with this there must be 1 neuron in the output layer.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet.in_features">
<span class="sig-name descname"><span class="pre">in_features</span></span><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.in_features" title="Permalink to this definition"></a></dt>
<dd><p>Input number of neuron activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet.num_neurons_list">
<span class="sig-name descname"><span class="pre">num_neurons_list</span></span><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.num_neurons_list" title="Permalink to this definition"></a></dt>
<dd><p>The number of neurons in consecutive fully connected layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Determines how the data will pass through the neural network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_num_neurons_list">
<span class="sig-name descname"><span class="pre">get_num_neurons_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet.get_num_neurons_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_num_neurons_list" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of neurons in consecutive fully connected layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Permalink to this definition"></a></dt>
<dd><p>Determines how the data will pass through the neural network. Returns the data received after processing by
the neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.tensor</em>) – The input activations tensor reduced to one dimension.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_in_features">
<span class="sig-name descname"><span class="pre">get_in_features</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet.get_in_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.single_mapping_net.SingleMappingNet.get_in_features" title="Permalink to this definition"></a></dt>
<dd><p>Returns the input number of neuron activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>in_features</strong> – Input number of neuron activations.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">get_num_neurons_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/single_mapping_net.html#SingleMappingNet.get_num_neurons_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of neurons in consecutive fully connected layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_neurons_list</strong> – The number of neurons in consecutive fully connected layers.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.mapping_nets.simultaneous_mapping_net">
<span id="simultaneous-mapping-net"></span><h2>simultaneous_mapping_net<a class="headerlink" href="#module-revelionn.mapping_nets.simultaneous_mapping_net" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_nets.simultaneous_mapping_net.</span></span><span class="sig-name descname"><span class="pre">LayerDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#LayerDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Module consisting of a 1x1 convolution layer, followed by a ReLU activation function, a global average pooling
layer, and a flattening layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – The number of input channels to the 1x1 convolution layer.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – The number of output channels from the 1x1 convolution layer.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.layers">
<span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.layers" title="Permalink to this definition"></a></dt>
<dd><p>A sequential container of the layers that make up this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#LayerDecoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.LayerDecoder.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the module.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#LayerDecoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id2" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The input tensor of shape (batch_size, in_channels, height, width).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of shape (batch_size, out_channels).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_nets.simultaneous_mapping_net.</span></span><span class="sig-name descname"><span class="pre">MappingModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#MappingModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule" title="Permalink to this definition"></a></dt>
<dd><p>A module representing a common fully connected part of a simultaneous mapping network and blocks of concepts.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.common_layers">
<span class="sig-name descname"><span class="pre">common_layers</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.common_layers" title="Permalink to this definition"></a></dt>
<dd><p>The shared layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.output_layers_list">
<span class="sig-name descname"><span class="pre">output_layers_list</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.output_layers_list" title="Permalink to this definition"></a></dt>
<dd><p>A list of output layers, each of which maps the input tensor to an output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.ModuleList</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.sigmoid">
<span class="sig-name descname"><span class="pre">sigmoid</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.sigmoid" title="Permalink to this definition"></a></dt>
<dd><p>The sigmoid function used to transform the output tensor(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.Sigmoid</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.generate_layers">
<span class="sig-name descname"><span class="pre">generate_layers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#MappingModule.generate_layers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.generate_layers" title="Permalink to this definition"></a></dt>
<dd><p>Generates a list of PyTorch layers based on the number of neurons in each layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#MappingModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.MappingModule.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the module.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#MappingModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id3" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor(s).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">generate_layers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#MappingModule.generate_layers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id4" title="Permalink to this definition"></a></dt>
<dd><p>Generates a list of PyTorch layers based on the number of neurons in each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of PyTorch layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[nn.Module]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_nets.simultaneous_mapping_net.</span></span><span class="sig-name descname"><span class="pre">SimultaneousMappingNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation_extractor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet" title="Permalink to this definition"></a></dt>
<dd><p>Simultaneous Mapping Network for RevelioNN.</p>
<p>Receives an input tuple of activations of the specified convolutional network layers, after which the input tensors
are processed by decoder blocks. The output tensors of each of the decoders are concatenated and fed into a common
fully connected part of the network. This is followed by blocks of concepts (one for each of the concepts), which
are sets of fully connected layers having 1 neuron and a sigmoid at the output.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoder_channels">
<span class="sig-name descname"><span class="pre">decoder_channels</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoder_channels" title="Permalink to this definition"></a></dt>
<dd><p>The number of decoder channels. The output number of channels of the convolutional layer of the decoder or the
output number of neurons of the decoder of the fully connected layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_shared_neurons">
<span class="sig-name descname"><span class="pre">num_shared_neurons</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_shared_neurons" title="Permalink to this definition"></a></dt>
<dd><p>The number of neurons in consecutive fully connected layers of the common part of the network
(internal representation of the simultaneous extraction network).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_output_neurons">
<span class="sig-name descname"><span class="pre">num_output_neurons</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_output_neurons" title="Permalink to this definition"></a></dt>
<dd><p>The number of neurons in consecutive fully connected layers of each of the concept blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_outs">
<span class="sig-name descname"><span class="pre">num_outs</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.num_outs" title="Permalink to this definition"></a></dt>
<dd><p>The number of outputs of the simultaneous extraction network. It is determined by the number of extracted
concepts.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoders">
<span class="sig-name descname"><span class="pre">decoders</span></span><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.decoders" title="Permalink to this definition"></a></dt>
<dd><p>Contains the generated decoder blocks in the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.ModuleList</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_decoder_channels">
<span class="sig-name descname"><span class="pre">get_decoder_channels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_decoder_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_decoder_channels" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of decoder channels.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_shared_neurons">
<span class="sig-name descname"><span class="pre">get_num_shared_neurons</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_shared_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_shared_neurons" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of neurons in consecutive fully connected layers of the common part of the network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_output_neurons">
<span class="sig-name descname"><span class="pre">get_num_output_neurons</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_output_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_output_neurons" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of neurons in consecutive fully connected layers of each of the concept blocks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_outs">
<span class="sig-name descname"><span class="pre">get_num_outs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_outs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_nets.simultaneous_mapping_net.SimultaneousMappingNet.get_num_outs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of outputs of the simultaneous extraction network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activations</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id5" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass through the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>activations</strong> (<em>tuple</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A list of input activations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">get_decoder_channels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_decoder_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id6" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of decoder channels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of decoder channels. The output number of channels of the convolutional layer of the decoder or
the output number of neurons of the decoder of the fully connected layer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">get_num_output_neurons</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_output_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id7" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of output neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of neurons in consecutive fully connected layers of each of the concept blocks.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id8">
<span class="sig-name descname"><span class="pre">get_num_outs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_outs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id8" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of outputs of the simultaneous extraction network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of outputs of the simultaneous extraction network.
It is determined by the number of extracted concepts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">get_num_shared_neurons</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_nets/simultaneous_mapping_net.html#SimultaneousMappingNet.get_num_shared_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id9" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of shared neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of neurons in consecutive fully connected layers of the common part of the network
(internal representation of the simultaneous extraction network).</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.main_module">
<span id="main-module"></span><h2>main_module<a class="headerlink" href="#module-revelionn.main_module" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.main_module.</span></span><span class="sig-name descname"><span class="pre">MainModelProcessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing" title="Permalink to this definition"></a></dt>
<dd><p>Class for training, evaluation and processing the main network model.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.device" title="Permalink to this definition"></a></dt>
<dd><p>Tensor processing device.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.main_net">
<span class="sig-name descname"><span class="pre">main_net</span></span><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.main_net" title="Permalink to this definition"></a></dt>
<dd><p>The model of the main neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.classes">
<span class="sig-name descname"><span class="pre">classes</span></span><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.classes" title="Permalink to this definition"></a></dt>
<dd><p>Names of neural network output classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_to_model_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads the weights of the neural network model from a file.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_model(patience,</span> <span class="pre">epochs,</span> <span class="pre">file_name,</span> <span class="pre">class_label_name,</span> <span class="pre">module_name,</span></span></dt>
<dd><blockquote>
<div><p>main_net_class, transformation_name, img_size, num_channels)</p>
</div></blockquote>
<p>Training and validation of the main neural network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.evaluate_model">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.evaluate_model" title="Permalink to this definition"></a></dt>
<dd><p>Evaluation of the model on the test set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.get_main_net">
<span class="sig-name descname"><span class="pre">get_main_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_main_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.get_main_net" title="Permalink to this definition"></a></dt>
<dd><p>Returns the main neural network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.get_class_labels">
<span class="sig-name descname"><span class="pre">get_class_labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_class_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.get_class_labels" title="Permalink to this definition"></a></dt>
<dd><p>Returns names of neural network output classes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.get_device">
<span class="sig-name descname"><span class="pre">get_device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.get_device" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current tensor processing device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id10">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id10" title="Permalink to this definition"></a></dt>
<dd><p>Evaluation of the model on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>test_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Training data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>test_loss</strong> (<em>float</em>) – Test loss.</p></li>
<li><p><strong>test_acc</strong> (<em>float</em>) – Accuracy on the test set.</p></li>
<li><p><strong>test_auc</strong> (<em>float</em>) – ROC AUC on the test set.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id11">
<span class="sig-name descname"><span class="pre">get_class_labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_class_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id11" title="Permalink to this definition"></a></dt>
<dd><p>Returns names of neural network output classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>classes</strong> – Names of neural network output classes.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id12">
<span class="sig-name descname"><span class="pre">get_device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id12" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current tensor processing device.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Tensor processing device.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id13">
<span class="sig-name descname"><span class="pre">get_main_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.get_main_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id13" title="Permalink to this definition"></a></dt>
<dd><p>Returns the main neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>main_net</strong> – The main neural network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>MainNet(nn.Module)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id14">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_to_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id14" title="Permalink to this definition"></a></dt>
<dd><p>Loads the weights of the neural network model from a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path_to_model</strong> (<em>str</em>) – The path to the file containing weights.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.main_module.MainModelProcessing.train_model">
<span class="sig-name descname"><span class="pre">train_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/main_module.html#MainModelProcessing.train_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.main_module.MainModelProcessing.train_model" title="Permalink to this definition"></a></dt>
<dd><p>Training and validation of the main neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patience</strong> (<em>int</em>) – How many epochs to wait after last time validation loss improved.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – The number of training epochs of the main neural network.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The name of the file in which the parameters of the trained model will be saved.</p></li>
<li><p><strong>class_label</strong> (<em>str</em>) – The name of the label of the class used for training.</p></li>
<li><p><strong>module_name</strong> (<em>str</em>) – The name of the file containing the main network class.</p></li>
<li><p><strong>main_net_class</strong> (<em>str</em>) – Name of the main network class.</p></li>
<li><p><strong>transformation_name</strong> (<em>str</em>) – Name of the variable storing transformations.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – The size of the image side.</p></li>
<li><p><strong>num_channels</strong> (<em>int</em>) – The number of image channels.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.activation_extraction">
<span id="activation-extraction"></span><h2>activation_extraction<a class="headerlink" href="#module-revelionn.activation_extraction" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.activation_extraction.</span></span><span class="sig-name descname"><span class="pre">ActivationExtractor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_types</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_concatenate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor" title="Permalink to this definition"></a></dt>
<dd><p>Class for identifying layers of a convolutional neural network and for extracting activations produced during
network inference from a selected set of layers.</p>
<p>It has two modes of operation:
1. Activations of the given layers are concatenated and transformed to a one-dimensional tensor.
It is used to train a single mapping network.
2. Activations of the specified layers are returned as a tuple without transformations.
It is used for training simultaneous mapping network.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.device" title="Permalink to this definition"></a></dt>
<dd><p>Tensor processing device.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.main_net">
<span class="sig-name descname"><span class="pre">main_net</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.main_net" title="Permalink to this definition"></a></dt>
<dd><p>The model of the main neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.layers_types_dict">
<span class="sig-name descname"><span class="pre">layers_types_dict</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.layers_types_dict" title="Permalink to this definition"></a></dt>
<dd><p>The dictionary contains the names of layer types as keys, and the corresponding values represent
the layer class in PyTorch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.layers_types">
<span class="sig-name descname"><span class="pre">layers_types</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.layers_types" title="Permalink to this definition"></a></dt>
<dd><p>Types of layers to be found in the hierarchy of network layers. This list should contain only the names of the
layer types that are in ‘layers_types_dict’ dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.layers_dict">
<span class="sig-name descname"><span class="pre">layers_dict</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.layers_dict" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of neural network layers. The keys of this dictionary represent the unique names of each of the
layers of the convolutional network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.activation">
<span class="sig-name descname"><span class="pre">activation</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.activation" title="Permalink to this definition"></a></dt>
<dd><p>Activation values of the specified layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.layers_for_research">
<span class="sig-name descname"><span class="pre">layers_for_research</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.layers_for_research" title="Permalink to this definition"></a></dt>
<dd><p>A list of the studied convolutional network layers. Set by the user with keys in the ‘layers_dict’ dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.is_concatenate">
<span class="sig-name descname"><span class="pre">is_concatenate</span></span><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.is_concatenate" title="Permalink to this definition"></a></dt>
<dd><p>Logical parameter that sets the mode of operation of ActivationExtractor. If True, the activations of the given
layers are concatenated and transformed to a one-dimensional tensor. If False, the activations of the specified
layers are returned as a tuple without transformations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_layers_types">
<span class="sig-name descname"><span class="pre">get_layers_types</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_types"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_types" title="Permalink to this definition"></a></dt>
<dd><p>Returns user-defined types of layers to be found in the hierarchy of network layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.find_layer_predicate_recursive">
<span class="sig-name descname"><span class="pre">find_layer_predicate_recursive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.find_layer_predicate_recursive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.find_layer_predicate_recursive" title="Permalink to this definition"></a></dt>
<dd><p>Recursively searches through a PyTorch model and returns a list of all layers that satisfy a given predicate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.find_layers_types_recursive">
<span class="sig-name descname"><span class="pre">find_layers_types_recursive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_types</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.find_layers_types_recursive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.find_layers_types_recursive" title="Permalink to this definition"></a></dt>
<dd><p>Recursively searches through a PyTorch model and returns a list of all layers that are of a given type or types.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.create_layers_dict">
<span class="sig-name descname"><span class="pre">create_layers_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cur_layers_types</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.create_layers_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.create_layers_dict" title="Permalink to this definition"></a></dt>
<dd><p>Creates a dictionary of PyTorch layers of the given types from a PyTorch model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_layers_dict">
<span class="sig-name descname"><span class="pre">get_layers_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_dict" title="Permalink to this definition"></a></dt>
<dd><p>Returns a dictionary of neural network layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_layer_name_by_number">
<span class="sig-name descname"><span class="pre">get_layer_name_by_number</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layer_name_by_number"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_layer_name_by_number" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer name in the layers dictionary by its number.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_activation">
<span class="sig-name descname"><span class="pre">get_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_activation" title="Permalink to this definition"></a></dt>
<dd><p>Saves the values of layer activations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.register_hooks">
<span class="sig-name descname"><span class="pre">register_hooks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.register_hooks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.register_hooks" title="Permalink to this definition"></a></dt>
<dd><p>Registers the interception of activations of the studied layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.count_num_activations">
<span class="sig-name descname"><span class="pre">count_num_activations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height_img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.count_num_activations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.count_num_activations" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of activations of neurons of the studied layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_activations">
<span class="sig-name descname"><span class="pre">get_activations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_activations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_activations" title="Permalink to this definition"></a></dt>
<dd><p>Returns the activation tensor of the studied layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.set_layers_for_research">
<span class="sig-name descname"><span class="pre">set_layers_for_research</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.set_layers_for_research"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.set_layers_for_research" title="Permalink to this definition"></a></dt>
<dd><p>Sets the list of layers to be examined.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_layers_for_research">
<span class="sig-name descname"><span class="pre">get_layers_for_research</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_for_research"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_layers_for_research" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of the layers under study.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.activation_extraction.ActivationExtractor.get_main_net">
<span class="sig-name descname"><span class="pre">get_main_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_main_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.activation_extraction.ActivationExtractor.get_main_net" title="Permalink to this definition"></a></dt>
<dd><p>Returns the main neural network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id15">
<span class="sig-name descname"><span class="pre">count_num_activations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height_img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.count_num_activations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id15" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of activations of neurons of the studied layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_channels</strong> (<em>int</em>) – Number of channels in the input image.</p></li>
<li><p><strong>width_img</strong> (<em>int</em>) – Width of the input image.</p></li>
<li><p><strong>height_img</strong> (<em>int</em>) – Height of the input image.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>num_activations</strong> – Number of neuron activations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id16">
<span class="sig-name descname"><span class="pre">create_layers_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cur_layers_types</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.create_layers_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id16" title="Permalink to this definition"></a></dt>
<dd><p>Creates a dictionary of PyTorch layers of the given types from a PyTorch model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model to extract layers from.</p></li>
<li><p><strong>cur_layers_types</strong> (<em>list</em>) – A list of strings representing the types of layers to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary mapping layer names to PyTorch layers of the corresponding type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id17">
<span class="sig-name descname"><span class="pre">find_layer_predicate_recursive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.find_layer_predicate_recursive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id17" title="Permalink to this definition"></a></dt>
<dd><p>Recursively searches through a PyTorch model and returns a list of all layers that satisfy a given predicate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model to search through.</p></li>
<li><p><strong>predicate</strong> (<em>function</em>) – A function that takes a PyTorch layer as input and returns a boolean indicating whether or not the layer
satisfies the predicate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of all layers in the model that satisfy the given predicate.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id18">
<span class="sig-name descname"><span class="pre">find_layers_types_recursive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_types</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.find_layers_types_recursive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id18" title="Permalink to this definition"></a></dt>
<dd><p>Recursively searches through a PyTorch model and returns a list of all layers that are of a given type or types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model to search through.</p></li>
<li><p><strong>layers_types</strong> (<em>list</em>) – A list of PyTorch layer types to search for.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of all layers in the model that are of one of the given layer types.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id19">
<span class="sig-name descname"><span class="pre">get_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id19" title="Permalink to this definition"></a></dt>
<dd><p>Saves the values of layer activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – User-defined name of the neural network layer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>hook</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id20">
<span class="sig-name descname"><span class="pre">get_activations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_activations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id20" title="Permalink to this definition"></a></dt>
<dd><p>Returns the activation tensor of the studied layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mapping_batch_size</strong> (<em>int</em>) – The size of the data batch for training the mapping network.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>cur_acts</strong> – Activations of the studied layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor or tuple[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id21">
<span class="sig-name descname"><span class="pre">get_layer_name_by_number</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layer_name_by_number"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id21" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer name in the layers dictionary by its number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>number</strong> (<em>int</em>) – Layer number.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Layer name.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id22">
<span class="sig-name descname"><span class="pre">get_layers_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id22" title="Permalink to this definition"></a></dt>
<dd><p>Returns a dictionary of neural network layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>layers_dict</strong> – A dictionary of neural network layers.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id23">
<span class="sig-name descname"><span class="pre">get_layers_for_research</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_for_research"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id23" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of the layers under study.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>layers_for_research</strong> – The list of layers to be examined.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id24">
<span class="sig-name descname"><span class="pre">get_layers_types</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_layers_types"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id24" title="Permalink to this definition"></a></dt>
<dd><p>Returns user-defined types of layers to be found in the hierarchy of network layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Layers types.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id25">
<span class="sig-name descname"><span class="pre">get_main_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.get_main_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id25" title="Permalink to this definition"></a></dt>
<dd><p>Returns the main neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>main_net</strong> – The main neural network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id26">
<span class="sig-name descname"><span class="pre">register_hooks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.register_hooks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id26" title="Permalink to this definition"></a></dt>
<dd><p>Registers the interception of activations of the studied layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id27">
<span class="sig-name descname"><span class="pre">set_layers_for_research</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/activation_extraction.html#ActivationExtractor.set_layers_for_research"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id27" title="Permalink to this definition"></a></dt>
<dd><p>Sets the list of layers to be examined.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>layers</strong> (<em>list</em><em>[</em><em>str</em><em>] or </em><em>list</em><em>[</em><em>int</em><em>]</em>) – Contains layer names or layer numbers (indexing from 0) available in the dictionary of layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.mapping_module">
<span id="mapping-module"></span><h2>mapping_module<a class="headerlink" href="#module-revelionn.mapping_module" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_module.</span></span><span class="sig-name descname"><span class="pre">MappingModelProcessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation_extractor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing" title="Permalink to this definition"></a></dt>
<dd><p>Class for training, evaluation and processing the mapping network model.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.device" title="Permalink to this definition"></a></dt>
<dd><p>Tensor processing device.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.activation_extractor">
<span class="sig-name descname"><span class="pre">activation_extractor</span></span><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.activation_extractor" title="Permalink to this definition"></a></dt>
<dd><p>Class for identifying layers of a convolutional neural network and for extracting activations produced during
network inference from a selected set of layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>MainNetExplanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.mapping_net">
<span class="sig-name descname"><span class="pre">mapping_net</span></span><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.mapping_net" title="Permalink to this definition"></a></dt>
<dd><p>The model of the mapping neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>MappingNet(nn.Module)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.class_labels">
<span class="sig-name descname"><span class="pre">class_labels</span></span><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.class_labels" title="Permalink to this definition"></a></dt>
<dd><p>Names of mapping network output classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_model_single(train_loader,</span> <span class="pre">valid_loader,</span> <span class="pre">optimizer,</span> <span class="pre">early_stopping,</span> <span class="pre">epochs,</span> <span class="pre">filename,</span> <span class="pre">class_label,</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">main_net_module_name,</span> <span class="pre">main_net_class,</span> <span class="pre">main_model_filename,</span> <span class="pre">transformation_name,</span> <span class="pre">img_size,</span> <span class="pre">num_channels)</span></span></dt>
<dd><p>Trains a single mapping network for a given concept.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_model_simultaneous(train_loader,</span> <span class="pre">valid_loader,</span> <span class="pre">optimizer,</span> <span class="pre">early_stopping,</span> <span class="pre">epochs,</span> <span class="pre">filename,</span> <span class="pre">class_labels,</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">main_net_module_name,</span> <span class="pre">main_net_class,</span> <span class="pre">main_model_filename,</span> <span class="pre">transformation_name,</span> <span class="pre">img_size,</span> <span class="pre">num_channels)</span></span></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_model_semisupervised(train_loader,</span> <span class="pre">valid_loader,</span> <span class="pre">optimizer,</span> <span class="pre">early_stopping,</span> <span class="pre">epochs,</span> <span class="pre">semantic_loss,</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">sem_loss_weight,</span> <span class="pre">filename,</span> <span class="pre">class_labels,</span> <span class="pre">main_net_module_name,</span> <span class="pre">main_net_class,</span> <span class="pre">main_model_filename,</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">transformation_name,</span> <span class="pre">img_size,</span> <span class="pre">num_channels)</span></span></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts using semi-supervised learning, in which a
semantic loss is calculated for unlabeled samples, taking into account the relationships between the concepts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.evaluate_model">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.evaluate_model" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the mapping network model on the test set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.get_mapping_net">
<span class="sig-name descname"><span class="pre">get_mapping_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_mapping_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.get_mapping_net" title="Permalink to this definition"></a></dt>
<dd><p>Returns the mapping network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.get_class_labels">
<span class="sig-name descname"><span class="pre">get_class_labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_class_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.get_class_labels" title="Permalink to this definition"></a></dt>
<dd><p>Returns names of mapping network output classes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.get_activation_extractor">
<span class="sig-name descname"><span class="pre">get_activation_extractor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_activation_extractor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.get_activation_extractor" title="Permalink to this definition"></a></dt>
<dd><p>Returns the ActivationExtractor object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_to_model_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads weights and class labels of the mapping network model from a file.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id28">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id28" title="Permalink to this definition"></a></dt>
<dd><p>Evaluation of the model on the test set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id29">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id29" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the mapping network model on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>test_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Training data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>res_test_concepts_auc</strong> (<em>list[float]</em>) – ROC AUC values for each of the concepts.</p></li>
<li><p><strong>test_auc</strong> (<em>float</em>) – The ROC AUC value of a single mapping network or the ROC AUC value for all labels of a simultaneous mapping
network.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id30">
<span class="sig-name descname"><span class="pre">get_activation_extractor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_activation_extractor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id30" title="Permalink to this definition"></a></dt>
<dd><p>Returns the ActivationExtractor object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Class for identifying layers of a convolutional neural network and for extracting activations produced
during network inference.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor" title="revelionn.activation_extraction.ActivationExtractor">ActivationExtractor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id31">
<span class="sig-name descname"><span class="pre">get_class_labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_class_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id31" title="Permalink to this definition"></a></dt>
<dd><p>Returns names of mapping network output classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>classes</strong> – Names of mapping network output classes.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id32">
<span class="sig-name descname"><span class="pre">get_mapping_net</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.get_mapping_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id32" title="Permalink to this definition"></a></dt>
<dd><p>Returns the mapping network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mapping_net</strong> – The mapping network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id33">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_to_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id33" title="Permalink to this definition"></a></dt>
<dd><p>Loads weights and class labels of the mapping network model from a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path_to_model</strong> (<em>str</em>) – The path to the file containing weights.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.train_model_semisupervised">
<span class="sig-name descname"><span class="pre">train_model_semisupervised</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">semantic_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sem_loss_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_model_filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.train_model_semisupervised"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.train_model_semisupervised" title="Permalink to this definition"></a></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts using semi-supervised learning, in which a
semantic loss is calculated for unlabeled samples, taking into account the relationships between the concepts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Training data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>valid_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Validation data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – The used weight optimizer of the mapping network.</p></li>
<li><p><strong>early_stopping</strong> (<a class="reference internal" href="#revelionn.early_stopping.EarlyStopping" title="revelionn.early_stopping.EarlyStopping"><em>EarlyStopping</em></a>) – Class to stop training when validation loss stops improving.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – The number of training epochs of the mapping neural network.</p></li>
<li><p><strong>semantic_loss</strong> (<em>semantic_loss_pytorch.SemanticLoss</em>) – An object of the semantic loss class, for initialization of which it is necessary to use the generated .sdd
and .vtree.</p></li>
<li><p><strong>sem_loss_weight</strong> (<em>float</em>) – The contribution of semantic loss to the overall loss function.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The name of the file in which the parameters of the trained model will be saved.</p></li>
<li><p><strong>class_labels</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – Names of class labels used for training.</p></li>
<li><p><strong>main_net_module_name</strong> (<em>str</em>) – The name of the file containing the main network class.</p></li>
<li><p><strong>main_net_class</strong> (<em>str</em>) – Name of the main network class.</p></li>
<li><p><strong>main_model_filename</strong> (<em>str</em>) – The file containing the parameters of the main network model.</p></li>
<li><p><strong>transformation_name</strong> (<em>str</em>) – Name of the variable storing transformations.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – The size of the image side.</p></li>
<li><p><strong>num_channels</strong> (<em>int</em>) – The number of image channels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.train_model_simultaneous">
<span class="sig-name descname"><span class="pre">train_model_simultaneous</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_model_filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.train_model_simultaneous"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.train_model_simultaneous" title="Permalink to this definition"></a></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Training data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>valid_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Validation data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – The used weight optimizer of the mapping network.</p></li>
<li><p><strong>early_stopping</strong> (<a class="reference internal" href="#revelionn.early_stopping.EarlyStopping" title="revelionn.early_stopping.EarlyStopping"><em>EarlyStopping</em></a>) – Class to stop training when validation loss stops improving.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – The number of training epochs of the mapping neural network.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The name of the file in which the parameters of the trained model will be saved.</p></li>
<li><p><strong>class_labels</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – Names of class labels used for training.</p></li>
<li><p><strong>main_net_module_name</strong> (<em>str</em>) – The name of the file containing the main network class.</p></li>
<li><p><strong>main_net_class</strong> (<em>str</em>) – Name of the main network class.</p></li>
<li><p><strong>main_model_filename</strong> (<em>str</em>) – The file containing the parameters of the main network model.</p></li>
<li><p><strong>transformation_name</strong> (<em>str</em>) – Name of the variable storing transformations.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – The size of the image side.</p></li>
<li><p><strong>num_channels</strong> (<em>int</em>) – The number of image channels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_module.MappingModelProcessing.train_model_single">
<span class="sig-name descname"><span class="pre">train_model_single</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_model_filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_module.html#MappingModelProcessing.train_model_single"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_module.MappingModelProcessing.train_model_single" title="Permalink to this definition"></a></dt>
<dd><p>Trains a single mapping network for a given concept.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Training data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>valid_loader</strong> (<em>torch.utils.data.DataLoader</em>) – Validation data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – The used weight optimizer of the mapping network.</p></li>
<li><p><strong>early_stopping</strong> (<a class="reference internal" href="#revelionn.early_stopping.EarlyStopping" title="revelionn.early_stopping.EarlyStopping"><em>EarlyStopping</em></a>) – Class to stop training when validation loss stops improving.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – The number of training epochs of the mapping neural network.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The name of the file in which the parameters of the trained model will be saved.</p></li>
<li><p><strong>class_label</strong> (<em>str</em>) – The name of the label of the class used for training.</p></li>
<li><p><strong>main_net_module_name</strong> (<em>str</em>) – The name of the file containing the main network class.</p></li>
<li><p><strong>main_net_class</strong> (<em>str</em>) – Name of the main network class.</p></li>
<li><p><strong>main_model_filename</strong> (<em>str</em>) – The file containing the parameters of the main network model.</p></li>
<li><p><strong>transformation_name</strong> (<em>str</em>) – Name of the variable storing transformations.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – The size of the image side.</p></li>
<li><p><strong>num_channels</strong> (<em>int</em>) – The number of image channels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.mapping_trainer">
<span id="mapping-trainer"></span><h2>mapping_trainer<a class="headerlink" href="#module-revelionn.mapping_trainer" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.mapping_trainer.MappingTrainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.mapping_trainer.</span></span><span class="sig-name descname"><span class="pre">MappingTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_model_filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_types</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_save</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_train_csv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_valid_csv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_names_column</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_test_csv</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_trainer.MappingTrainer" title="Permalink to this definition"></a></dt>
<dd><p>Mapping Trainer class provides an interface for learning/evaluating mapping networks</p>
<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_trainer.MappingTrainer.train_single_model">
<span class="sig-name descname"><span class="pre">train_single_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.train_single_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_trainer.MappingTrainer.train_single_model" title="Permalink to this definition"></a></dt>
<dd><p>Trains a single mapping network for a given concept based on the activations of given layers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model">
<span class="sig-name descname"><span class="pre">train_simultaneous_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concepts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.train_simultaneous_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model" title="Permalink to this definition"></a></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts based on the activations of layers of
previously defined types.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">train_simultaneous_model_semisupervised(concepts,</span> <span class="pre">decoder_channels,</span> <span class="pre">num_shared_neurons,</span> <span class="pre">num_output_neurons,</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">semantic_loss,</span> <span class="pre">sem_loss_weight,</span> <span class="pre">unlabeled_samples)</span></span></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts using semi-supervised learning, in which a
semantic loss is calculated for unlabeled samples, taking into account the relationships between the concepts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_trainer.MappingTrainer.evaluate_model">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_trainer.MappingTrainer.evaluate_model" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the mapping network model on the test set using the ROC AUC.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id34">
<span class="sig-name descname"><span class="pre">evaluate_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.evaluate_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id34" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the mapping network model on the test set using the ROC AUC.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The ROC AUC value of a single mapping network or the ROC AUC value for all labels of a simultaneous mapping
network.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id35">
<span class="sig-name descname"><span class="pre">train_simultaneous_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concepts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.train_simultaneous_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id35" title="Permalink to this definition"></a></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts based on the activations of layers of
previously defined types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concepts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – The target concepts for which to train the mapping network.</p></li>
<li><p><strong>decoder_channels</strong> (<em>int</em>) – The number of decoder channels. The output number of channels of the convolutional layer of the decoder or
the output number of neurons of the decoder of the fully connected layer.</p></li>
<li><p><strong>num_shared_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of the common part of the network
(internal representation of the simultaneous extraction network).</p></li>
<li><p><strong>num_output_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of each of the concept blocks.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model_semisupervised">
<span class="sig-name descname"><span class="pre">train_simultaneous_model_semisupervised</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concepts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">semantic_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sem_loss_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unlabeled_samples</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.train_simultaneous_model_semisupervised"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.mapping_trainer.MappingTrainer.train_simultaneous_model_semisupervised" title="Permalink to this definition"></a></dt>
<dd><p>Trains a simultaneous mapping network for a given set of concepts using semi-supervised learning, in which a
semantic loss is calculated for unlabeled samples, taking into account the relationships between the concepts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concepts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – The target concepts for which to train the mapping network.</p></li>
<li><p><strong>decoder_channels</strong> (<em>int</em>) – The number of decoder channels. The output number of channels of the convolutional layer of the decoder or
the output number of neurons of the decoder of the fully connected layer.</p></li>
<li><p><strong>num_shared_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of the common part of the network
(internal representation of the simultaneous extraction network).</p></li>
<li><p><strong>num_output_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of each of the concept blocks.</p></li>
<li><p><strong>semantic_loss</strong> (<em>semantic_loss_pytorch.SemanticLoss</em>) – An object of the semantic loss class, for initialization of which it is necessary to use the generated .sdd
and .vtree.</p></li>
<li><p><strong>sem_loss_weight</strong> (<em>float</em>) – The contribution of semantic loss to the overall loss function.</p></li>
<li><p><strong>unlabeled_samples</strong> (<em>int</em><em> or </em><em>float</em>) – The number of unlabeled samples to include. If float, it represents the fraction of unlabeled samples.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id36">
<span class="sig-name descname"><span class="pre">train_single_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/mapping_trainer.html#MappingTrainer.train_single_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id36" title="Permalink to this definition"></a></dt>
<dd><p>Trains a single mapping network for a given concept based on the activations of given layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mapping_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers. The output layer should always have 1 neuron.</p></li>
<li><p><strong>concept</strong> (<em>str</em>) – The target concept for which to train the mapping network.</p></li>
<li><p><strong>layer_names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – A list of layer names to consider for training and evaluation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.concept_extraction">
<span id="concept-extraction"></span><h2>concept_extraction<a class="headerlink" href="#module-revelionn.concept_extraction" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.concept_extraction.</span></span><span class="sig-name descname"><span class="pre">ConceptExtractor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nxonto</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor" title="Permalink to this definition"></a></dt>
<dd><p>A class that provides concept extraction algorithms.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.ontology">
<span class="sig-name descname"><span class="pre">ontology</span></span><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.ontology" title="Permalink to this definition"></a></dt>
<dd><p>Ontology represented as a graph, where edge direction goes from superterm to subterm.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nxontology.NXOntology</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.trainer">
<span class="sig-name descname"><span class="pre">trainer</span></span><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.trainer" title="Permalink to this definition"></a></dt>
<dd><p>An instance of the MappingTrainer class that provides an interface for training mapping networks.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#revelionn.mapping_trainer.MappingTrainer" title="revelionn.mapping_trainer.MappingTrainer">MappingTrainer</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.create_subgraph">
<span class="sig-name descname"><span class="pre">create_subgraph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.create_subgraph"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.create_subgraph" title="Permalink to this definition"></a></dt>
<dd><p>Returns a subgraph containing all child nodes for a given, including this one.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.order_concepts">
<span class="sig-name descname"><span class="pre">order_concepts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.order_concepts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.order_concepts" title="Permalink to this definition"></a></dt>
<dd><p>Performs topological sorting of a subgraph formed by a given parent node (target concept).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.exhaustive_search">
<span class="sig-name descname"><span class="pre">exhaustive_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.exhaustive_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.exhaustive_search" title="Permalink to this definition"></a></dt>
<dd><p>Trains and evaluates mapping networks based on the activations of each of the specified layers of the network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.linear_search">
<span class="sig-name descname"><span class="pre">linear_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_layer_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.linear_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.linear_search" title="Permalink to this definition"></a></dt>
<dd><p>Trains and evaluates mapping networks based on the activations of each of the layers starting from the
specified one, until the value of the quality metric deteriorates over several layers (the value of patience).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.heuristic_search">
<span class="sig-name descname"><span class="pre">heuristic_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_layer_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.heuristic_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.heuristic_search" title="Permalink to this definition"></a></dt>
<dd><p>Due to the heuristic reduction of the set of specified layers, mapping networks are not trained for every
combination of layer-concept. Uses linear search.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">simultaneous_extraction(target_concept,</span> <span class="pre">decoder_channels,</span> <span class="pre">num_shared_neurons,</span> <span class="pre">num_output_neurons,</span></span></dt>
<dd><blockquote>
<div><p>sdd_path=None, vtree_path=None, sem_loss_weight=None, unlabeled_samples=None)</p>
</div></blockquote>
<p>Trains a mapping network that can simultaneously extract a set of relevant concepts from the entire set of
layers of specified types (the types are set when initializing the MappingTrainer instance).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id37">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_subgraph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.create_subgraph"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id37" title="Permalink to this definition"></a></dt>
<dd><p>Returns a subgraph containing all child nodes for a given node, including the given node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>networkx.Graph</em>) – The graph from which to extract the subgraph.</p></li>
<li><p><strong>node</strong> (<em>str</em>) – The node for which to create the subgraph.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A subgraph of <cite>graph</cite> containing all child nodes of <cite>node</cite>, including <cite>node</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>networkx.Graph</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id38">
<span class="sig-name descname"><span class="pre">exhaustive_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.exhaustive_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id38" title="Permalink to this definition"></a></dt>
<dd><p>Trains and evaluates mapping networks based on the activations of each of the specified layers of the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concept</strong> (<em>str</em>) – The concept for which to perform the search.</p></li>
<li><p><strong>layer_names</strong> (<em>list</em>) – A list of layer names to consider for training and evaluation.</p></li>
<li><p><strong>mapping_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in the mapping network.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dict containing the best layer name and the corresponding evaluation value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id39">
<span class="sig-name descname"><span class="pre">heuristic_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_layer_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.heuristic_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id39" title="Permalink to this definition"></a></dt>
<dd><p>Due to the heuristic reduction of the set of specified layers, mapping networks are not trained for every
combination of layer-concept. Uses linear search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_concept</strong> (<em>str</em>) – The target concept that should be obtained by ontological inference.
Mapping networks are trained to extract concepts relevant to the target concept.</p></li>
<li><p><strong>top_layer_num</strong> (<em>int</em>) – The starting layer number for training and evaluation.</p></li>
<li><p><strong>patience_layers</strong> (<em>int</em>) – The number of layers to tolerate deterioration in the quality metric.</p></li>
<li><p><strong>mapping_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in the mapping network.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary containing the best layer number and evaluation value for each concept in the subgraph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id40">
<span class="sig-name descname"><span class="pre">linear_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_layer_num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.linear_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id40" title="Permalink to this definition"></a></dt>
<dd><p>Trains and evaluates mapping networks based on the activations of each of the layers starting from the
specified one, until the value of the quality metric deteriorates over several layers (the value of patience).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concept</strong> (<em>str</em>) – The concept for which to perform the search.</p></li>
<li><p><strong>top_layer_num</strong> (<em>int</em>) – The starting layer number for training and evaluation.</p></li>
<li><p><strong>patience_layers</strong> (<em>int</em>) – The number of layers to tolerate deterioration in the quality metric.</p></li>
<li><p><strong>mapping_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in the mapping network.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the best layer number and the corresponding evaluation value.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id41">
<span class="sig-name descname"><span class="pre">order_concepts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.order_concepts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id41" title="Permalink to this definition"></a></dt>
<dd><p>Performs topological sorting of a subgraph formed by a given parent node (target concept).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_concept</strong> (<em>str</em>) – The target concept node for which to perform topological sorting.</p></li>
<li><p><strong>ontology</strong> (<em>nxontology.NXOntology</em>) – The ontology graph.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of concepts in topologically sorted order within the subgraph.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.concept_extraction.ConceptExtractor.simultaneous_extraction">
<span class="sig-name descname"><span class="pre">simultaneous_extraction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_shared_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sdd_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vtree_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sem_loss_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unlabeled_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/concept_extraction.html#ConceptExtractor.simultaneous_extraction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.concept_extraction.ConceptExtractor.simultaneous_extraction" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_concept</strong> (<em>str</em>) – The target concept that should be obtained by ontological inference.
Mapping networks are trained to extract concepts relevant to the target concept.</p></li>
<li><p><strong>decoder_channels</strong> (<em>int</em>) – The number of decoder channels. The output number of channels of the convolutional layer of the decoder or
the output number of neurons of the decoder of the fully connected layer.</p></li>
<li><p><strong>num_shared_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of the common part of the network
(internal representation of the simultaneous extraction network).</p></li>
<li><p><strong>num_output_neurons</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – The number of neurons in consecutive fully connected layers of each of the concept blocks.</p></li>
<li><p><strong>sdd_path</strong> (<em>str</em>) – The path to the .sdd file.</p></li>
<li><p><strong>vtree_path</strong> (<em>str</em>) – The path to the .vtree file.</p></li>
<li><p><strong>sem_loss_weight</strong> (<em>float</em>) – The contribution of semantic loss to the overall loss function.</p></li>
<li><p><strong>unlabeled_samples</strong> (<em>int</em><em> or </em><em>float</em>) – The number of unlabeled samples to include. If float, it represents the fraction of unlabeled samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>concepts_auc</strong> (<em>list[float]</em>) – ROC AUC values for each of the concepts.</p></li>
<li><p><strong>all_auc</strong> (<em>float</em>) – ROC AUC value for all labels of a simultaneous mapping network.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.datasets">
<span id="datasets"></span><h2>datasets<a class="headerlink" href="#module-revelionn.datasets" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.datasets.</span></span><span class="sig-name descname"><span class="pre">MultiLabeledImagesDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">annotations_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_column</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#MultiLabeledImagesDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset" title="Permalink to this definition"></a></dt>
<dd><p>A PyTorch dataset class for multi-labeled image data.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.img_labels">
<span class="sig-name descname"><span class="pre">img_labels</span></span><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.img_labels" title="Permalink to this definition"></a></dt>
<dd><p>A pandas DataFrame containing the image annotations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.img_dir">
<span class="sig-name descname"><span class="pre">img_dir</span></span><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.img_dir" title="Permalink to this definition"></a></dt>
<dd><p>The directory path containing the images.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.transform" title="Permalink to this definition"></a></dt>
<dd><p>A transform to apply to the image data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torchvision.transforms</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#MultiLabeledImagesDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.__len__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the total number of samples in the dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#MultiLabeledImagesDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the image and corresponding labels at the given index.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.MultiLabeledImagesDataset.labels">
<span class="sig-name descname"><span class="pre">labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#MultiLabeledImagesDataset.labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.MultiLabeledImagesDataset.labels" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of the target labels.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id42">
<span class="sig-name descname"><span class="pre">labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#MultiLabeledImagesDataset.labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id42" title="Permalink to this definition"></a></dt>
<dd><p>Return a list of the target labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list of target labels.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.datasets.</span></span><span class="sig-name descname"><span class="pre">SemiSupervisedImagesDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">annotations_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_column</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unlabeled_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#SemiSupervisedImagesDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset" title="Permalink to this definition"></a></dt>
<dd><p>A PyTorch dataset class for semi-supervised multi-labeled image data, inheriting from MultiLabeledImagesDataset.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.img_labels">
<span class="sig-name descname"><span class="pre">img_labels</span></span><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.img_labels" title="Permalink to this definition"></a></dt>
<dd><p>A pandas DataFrame containing the image annotations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.img_dir">
<span class="sig-name descname"><span class="pre">img_dir</span></span><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.img_dir" title="Permalink to this definition"></a></dt>
<dd><p>The directory path containing the images.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.transform" title="Permalink to this definition"></a></dt>
<dd><p>A transform to apply to the image data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torchvision.transforms</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.unlabeled_idx">
<span class="sig-name descname"><span class="pre">unlabeled_idx</span></span><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.unlabeled_idx" title="Permalink to this definition"></a></dt>
<dd><p>An array containing the indices of unlabeled samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">annotations_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_column</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unlabeled_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#SemiSupervisedImagesDataset.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the SemiSupervisedImagesDataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#SemiSupervisedImagesDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Get the image, corresponding labels, and unlabeled flag at the given index.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.datasets.SemiSupervisedImagesDataset.separate_unlabeled">
<span class="sig-name descname"><span class="pre">separate_unlabeled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_raw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_raw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_unlabeled</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#SemiSupervisedImagesDataset.separate_unlabeled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.SemiSupervisedImagesDataset.separate_unlabeled" title="Permalink to this definition"></a></dt>
<dd><p>Separate the labeled and unlabeled samples from the given data.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id43">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">separate_unlabeled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_raw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_raw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_unlabeled</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#SemiSupervisedImagesDataset.separate_unlabeled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id43" title="Permalink to this definition"></a></dt>
<dd><p>Separate the labeled and unlabeled samples from the given data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_raw</strong> (<em>torch.Tensor</em>) – The input data.</p></li>
<li><p><strong>y_raw</strong> (<em>torch.Tensor</em>) – The target labels.</p></li>
<li><p><strong>is_unlabeled</strong> (<em>torch.Tensor</em>) – The unlabeled flags indicating whether a sample is labeled (0) or unlabeled (1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the labeled data, labeled target labels, unlabeled data, and unlabeled target labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.datasets.create_dataloader">
<span class="sig-prename descclassname"><span class="pre">revelionn.datasets.</span></span><span class="sig-name descname"><span class="pre">create_dataloader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_to_csv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_names_column</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unlabeled_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/datasets.html#create_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.datasets.create_dataloader" title="Permalink to this definition"></a></dt>
<dd><p>Create a PyTorch DataLoader for loading the multi-labeled image dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path_to_csv</strong> (<em>str</em>) – The file path to the annotations file in CSV format.</p></li>
<li><p><strong>path_to_images</strong> (<em>str</em>) – The directory path containing the images.</p></li>
<li><p><strong>image_names_column</strong> (<em>str</em>) – The name of the column in the annotations file that contains the image names.</p></li>
<li><p><strong>target_columns</strong> (<em>str</em><em> or </em><em>list</em><em>[</em><em>str</em><em>]</em>) – The column name(s) of the target labels in the annotations file.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size for the DataLoader.</p></li>
<li><p><strong>num_workers</strong> (<em>int</em>) – The number of worker processes to use for data loading.</p></li>
<li><p><strong>transformation</strong> (<em>torchvision.transforms</em>) – A transform to apply to the image data.</p></li>
<li><p><strong>unlabeled_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>optional</em>) – The number of unlabeled samples to include. If float, it represents the fraction of unlabeled samples.
Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A PyTorch DataLoader for the multi-labeled image dataset.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.data.DataLoader</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the value of the parameter ‘unlabeled_samples’ is invalid.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-revelionn.early_stopping">
<span id="early-stopping"></span><h2>early_stopping<a class="headerlink" href="#module-revelionn.early_stopping" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.early_stopping.</span></span><span class="sig-name descname"><span class="pre">EarlyStopping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patience=7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trace_func=&lt;built-in</span> <span class="pre">function</span> <span class="pre">print&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/early_stopping.html#EarlyStopping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping" title="Permalink to this definition"></a></dt>
<dd><p>Early stopping class to stop training when validation loss stops improving.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.patience">
<span class="sig-name descname"><span class="pre">patience</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.patience" title="Permalink to this definition"></a></dt>
<dd><p>Number of epochs to wait for improvement before stopping.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.verbose">
<span class="sig-name descname"><span class="pre">verbose</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.verbose" title="Permalink to this definition"></a></dt>
<dd><p>If True, prints a message when validation loss decreases and the model is saved.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.counter">
<span class="sig-name descname"><span class="pre">counter</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.counter" title="Permalink to this definition"></a></dt>
<dd><p>Counter to track the number of epochs without improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.best_score">
<span class="sig-name descname"><span class="pre">best_score</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.best_score" title="Permalink to this definition"></a></dt>
<dd><p>Best score (negative validation loss) obtained so far.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.early_stop">
<span class="sig-name descname"><span class="pre">early_stop</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.early_stop" title="Permalink to this definition"></a></dt>
<dd><p>Flag indicating whether to stop the training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.val_loss_min">
<span class="sig-name descname"><span class="pre">val_loss_min</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.val_loss_min" title="Permalink to this definition"></a></dt>
<dd><p>Minimum validation loss observed so far.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.delta">
<span class="sig-name descname"><span class="pre">delta</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.delta" title="Permalink to this definition"></a></dt>
<dd><p>Minimum change in the monitored quantity to qualify as an improvement.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.trace_func">
<span class="sig-name descname"><span class="pre">trace_func</span></span><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.trace_func" title="Permalink to this definition"></a></dt>
<dd><p>A function used to trace the output message.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_loss</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/early_stopping.html#EarlyStopping.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.__call__" title="Permalink to this definition"></a></dt>
<dd><p>Call the early stopping class and determine whether to stop the training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.early_stopping.EarlyStopping.save_checkpoint">
<span class="sig-name descname"><span class="pre">save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_loss</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/early_stopping.html#EarlyStopping.save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.early_stopping.EarlyStopping.save_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Save the model checkpoint when the validation loss decreases.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id44">
<span class="sig-name descname"><span class="pre">save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_loss</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/early_stopping.html#EarlyStopping.save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id44" title="Permalink to this definition"></a></dt>
<dd><p>Save the model checkpoint when the validation loss decreases.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>val_loss</strong> (<em>float</em>) – The current validation loss value.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A message indicating that the validation loss decreased and the model is saved, or None.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-revelionn.occlusion">
<span id="occlusion"></span><h2>occlusion<a class="headerlink" href="#module-revelionn.occlusion" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="revelionn.occlusion.MultiLabelClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">revelionn.occlusion.</span></span><span class="sig-name descname"><span class="pre">MultiLabelClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_extractor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_transformation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/occlusion.html#MultiLabelClassifier"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.occlusion.MultiLabelClassifier" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="revelionn.occlusion.MultiLabelClassifier.classify_images">
<span class="sig-name descname"><span class="pre">classify_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_iter</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/occlusion.html#MultiLabelClassifier.classify_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.occlusion.MultiLabelClassifier.classify_images" title="Permalink to this definition"></a></dt>
<dd><p>Classify an input iterable of images, in the form of <cite>np.ndarray</cite>
matricies into a parallel iterable of label-to-confidence mappings
(dictionaries).</p>
<p>We expect input image matrices to come in either the <cite>[H, W]</cite> or
<cite>[H, W, C]</cite> dimension formats.</p>
<p>Each classification mapping should contain confidence values for each
label the configured model contains.
Implementations may act in a discrete manner whereby only one label is
marked with a <code class="docutils literal notranslate"><span class="pre">1</span></code> value (others being <code class="docutils literal notranslate"><span class="pre">0</span></code>), or in a continuous
manner whereby each label is given a confidence-like value in the
[0, 1] range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>array_iter</strong> – Iterable of images, as numpy arrays, to be
classified.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – Input arrays were not all of consistent
dimensionality.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator of dictionaries, parallel in association to the input
images. Each dictionary should map labels to associated
confidence values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.occlusion.MultiLabelClassifier.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/occlusion.html#MultiLabelClassifier.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.occlusion.MultiLabelClassifier.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Return a JSON-compliant dictionary that could be passed to this class’s
<code class="docutils literal notranslate"><span class="pre">from_config</span></code> method to produce an instance with identical
configuration.</p>
<p>In the most cases, this involves naming the keys of the dictionary
based on the initialization argument names as if it were to be passed
to the constructor via dictionary expansion.  In some cases, where it
doesn’t make sense to store some object constructor parameters are
expected to be supplied at as configuration values (i.e. must be
supplied at runtime), this method’s returned dictionary may leave those
parameters out. In such cases, the object’s <code class="docutils literal notranslate"><span class="pre">from_config</span></code>
class-method would also take additional positional arguments to fill in
for the parameters that this returned configuration lacks.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>JSON type compliant configuration dictionary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="revelionn.occlusion.MultiLabelClassifier.get_labels">
<span class="sig-name descname"><span class="pre">get_labels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/occlusion.html#MultiLabelClassifier.get_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.occlusion.MultiLabelClassifier.get_labels" title="Permalink to this definition"></a></dt>
<dd><p>Get the sequence of class labels that this classifier can classify
images into. This includes the negative or background label if the
classifier embodies such a concept.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Sequence of possible classifier labels.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – No model loaded.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.occlusion.perform_occlusion">
<span class="sig-prename descclassname"><span class="pre">revelionn.occlusion.</span></span><span class="sig-name descname"><span class="pre">perform_occlusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_extractor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threads</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/occlusion.html#perform_occlusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.occlusion.perform_occlusion" title="Permalink to this definition"></a></dt>
<dd><p>Highlights concepts extracted by the mapping network in the image by occlusion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>main_module</strong> (<a class="reference internal" href="#revelionn.main_module.MainModelProcessing" title="revelionn.main_module.MainModelProcessing"><em>MainModelProcessing</em></a>) – Class for training, evaluation and processing the main network model.</p></li>
<li><p><strong>mapping_module</strong> (<a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing" title="revelionn.mapping_module.MappingModelProcessing"><em>MappingModelProcessing</em></a>) – Class for training, evaluation and processing the mapping network model.</p></li>
<li><p><strong>activation_extractor</strong> (<a class="reference internal" href="#revelionn.activation_extraction.ActivationExtractor" title="revelionn.activation_extraction.ActivationExtractor"><em>ActivationExtractor</em></a>) – Class for identifying layers of a convolutional neural network and for extracting activations produced during
network inference.</p></li>
<li><p><strong>transformation</strong> (<em>torchvision.transforms</em>) – A transform to apply to the image.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – The size of the image side.</p></li>
<li><p><strong>path_to_img</strong> (<em>str</em>) – Image file path.</p></li>
<li><p><strong>window_size</strong> (<em>int</em>) – The block window size.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – The sliding window striding step.</p></li>
<li><p><strong>threads</strong> (<em>int</em>) – Optional number threads to use to enable parallelism in applying perturbation masks to an input image.
If 0, a negative value, or None, work will be performed on the main-thread in-line.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>plt</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>matplotlib.pyplot</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-revelionn.utils.explanation">
<span id="utils-explanation"></span><h2>utils.explanation<a class="headerlink" href="#module-revelionn.utils.explanation" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.explanation.explain_target_concept">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.explanation.</span></span><span class="sig-name descname"><span class="pre">explain_target_concept</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extracted_concepts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_probabilities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concepts_map</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jar_filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ontology_filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_to_temp_files</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/explanation.html#explain_target_concept"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.explanation.explain_target_concept" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>extracted_concepts</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – Concepts relevant to the target concept, which are extracted by the mapping network.</p></li>
<li><p><strong>mapping_probabilities</strong> (<em>list</em><em>[</em><em>float</em><em>]</em>) – The probabilities, obtained from the output of the sigmoid, of each of the extracted concepts relevant to the
target concept.</p></li>
<li><p><strong>concepts_map</strong> (<em>dict</em>) – Dictionary whose keys are the names of the attributes of the dataset, and the values are the corresponding
concepts of the ontology.</p></li>
<li><p><strong>target_concept</strong> (<em>str</em>) – The concept of ontology, which should be obtained by ontological inference from the extracted concepts.</p></li>
<li><p><strong>jar_filepath</strong> (<em>str</em>) – Path to the script (file onto_justify.jar) that generates explanations based on the ontology.</p></li>
<li><p><strong>ontology_filepath</strong> (<em>str</em>) – Path to the OWL ontology file.</p></li>
<li><p><strong>path_to_temp_files</strong> – Temporary files directory for storing observations and explanations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>justifications</strong> – A set of obtained justifications of the target class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.explanation.extract_concepts_from_img">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.explanation.</span></span><span class="sig-name descname"><span class="pre">extract_concepts_from_img</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mapping_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/explanation.html#extract_concepts_from_img"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.explanation.extract_concepts_from_img" title="Permalink to this definition"></a></dt>
<dd><p>Extracts a set of concepts present in a given image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>main_module</strong> (<a class="reference internal" href="#revelionn.main_module.MainModelProcessing" title="revelionn.main_module.MainModelProcessing"><em>MainModelProcessing</em></a>) – Class for training, evaluation and processing the main network model.</p></li>
<li><p><strong>mapping_module</strong> (<a class="reference internal" href="#revelionn.mapping_module.MappingModelProcessing" title="revelionn.mapping_module.MappingModelProcessing"><em>MappingModelProcessing</em></a>) – Class for training, evaluation and processing the mapping network model.</p></li>
<li><p><strong>img</strong> (<em>PIL.Image</em>) – Class that represents a PIL image.</p></li>
<li><p><strong>transformation</strong> (<em>torchvision.transforms</em>) – A transform to apply to the image.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>main_concept</strong> (<em>list[str]</em>) – Target concept extracted by the convolutional network.</p></li>
<li><p><strong>extracted_concepts</strong> (<em>list[str]</em>) – Concepts relevant to the target concept, which are extracted by the mapping network.</p></li>
<li><p><strong>mapping_probabilities</strong> (<em>list[float]</em>) – The probabilities, obtained from the output of the sigmoid, of each of the extracted concepts relevant to the
target concept.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.explanation.to_main_observation">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.explanation.</span></span><span class="sig-name descname"><span class="pre">to_main_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/explanation.html#to_main_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.explanation.to_main_observation" title="Permalink to this definition"></a></dt>
<dd><p>Formats a string from the name of the target concept to be parsed by the justifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>concept</strong> (<em>str</em>) – Name of the target concept.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>String from the name of the target concept to be parsed by the justifier.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.explanation.to_mapping_observation">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.explanation.</span></span><span class="sig-name descname"><span class="pre">to_mapping_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">concept</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/explanation.html#to_mapping_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.explanation.to_mapping_observation" title="Permalink to this definition"></a></dt>
<dd><p>Formats a string from the name of the concept relevant to the target concept, which will be parsed by the justifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concept</strong> (<em>str</em>) – Name of the concept relevant to the target concept.</p></li>
<li><p><strong>probability</strong> (<em>float</em>) – The probability of the concept obtained at the output of the sigmoid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>String from the name of the concept relevant to the target concept, which will be parsed by the justifier.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-revelionn.utils.model">
<span id="utils-model"></span><h2>utils.model<a class="headerlink" href="#module-revelionn.utils.model" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.model.convert_to_rvl_format">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.model.</span></span><span class="sig-name descname"><span class="pre">convert_to_rvl_format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_net_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformation_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/model.html#convert_to_rvl_format"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.model.convert_to_rvl_format" title="Permalink to this definition"></a></dt>
<dd><p>Converts the pre-trained main network model to RevelioNN format. Creates the converted model as an RVL file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>main_model</strong> (<em>torch.nn.Module</em>) – Main network model with loaded weights.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – Filename (path) to save the converted model.</p></li>
<li><p><strong>class_label</strong> (<em>str</em>) – Name of the output class label of the main network.</p></li>
<li><p><strong>module_name</strong> (<em>str</em>) – Name of the module (.py file name) containing the class of the main network.</p></li>
<li><p><strong>main_net_class</strong> (<em>str</em>) – Name of the main network class.</p></li>
<li><p><strong>transformation_name</strong> (<em>str</em>) – Name of the variable storing transformations.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – Size of the image side.</p></li>
<li><p><strong>num_channels</strong> (<em>int</em>) – Number of image channels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.model.load_main_model">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.model.</span></span><span class="sig-name descname"><span class="pre">load_main_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_model_filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/model.html#load_main_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.model.load_main_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads the main network model in RevelioNN format from a file. Initializes and returns a class to work with
the main net, as well as a transformation object and image size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>main_model_filepath</strong> (<em>str</em>) – File path containing the parameters of the main network model.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Tensor processing device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>main_module</strong> (<em>MainModelProcessing</em>) – Class for training, evaluation and processing the main network model.</p></li>
<li><p><strong>transformation</strong> (<em>torchvision.transforms</em>) – A transform to apply to the images.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – Size of the image side.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="revelionn.utils.model.load_mapping_model">
<span class="sig-prename descclassname"><span class="pre">revelionn.utils.model.</span></span><span class="sig-name descname"><span class="pre">load_mapping_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mapping_model_filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_models_directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/revelionn/utils/model.html#load_mapping_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#revelionn.utils.model.load_mapping_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads the mapping network model from a file. Initializes and returns a class to work with the main net,
as well as a transformation object and image size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mapping_model_filepath</strong> (<em>str</em>) – File path containing the parameters of the mapping network model.</p></li>
<li><p><strong>main_models_directory</strong> (<em>str</em>) – The directory containing the .py files in which the main network classes are defined.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Tensor processing device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>main_module</strong> (<em>MainModelProcessing</em>) – Class for training, evaluation and processing the main network model.</p></li>
<li><p><strong>mapping_module</strong> (<em>MappingModelProcessing</em>) – Class for training, evaluation and processing the mapping network model.</p></li>
<li><p><strong>activation_extractor</strong> (<em>ActivationExtractor</em>) – Class for identifying layers of the main network and for extracting activations produced during
network inference.</p></li>
<li><p><strong>transformation</strong> (<em>torchvision.transforms</em>) – A transform to apply to the images.</p></li>
<li><p><strong>img_size</strong> (<em>int</em>) – Size of the image side.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="data.html" class="btn btn-neutral float-left" title="Data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, RevelioNN authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>